ai_test_foundation ‚Äî Optimization Phase

Module: SmartLocator + AIHealer Optimization
Owner: Ram
Mentor: Yogi (via ChatGPT)
Repository: ai_test_foundation

üéØ Objective

Optimize the SmartLocator and AIHealer components for:

Performance (faster healing, fewer redundant AI calls)

Reliability (error resilience, clean fallback mechanisms)

Efficiency (cache reuse, batch prompt handling, logging improvements)

Maintainability (cleaner method-level structure and comments)

You will not change architecture, but refactor & harden both modules to enterprise-grade stability.

üß† Background Context

The current SmartLocator and AIHealer work perfectly for self-healing DOM-based locator repair.
However, they call the AI provider repeatedly for similar repair requests, and some edge cases (timeouts, invalid responses, rate limits) need more robust handling.

Both components live under:

core/
‚îú‚îÄ‚îÄ smart_locator/
‚îÇ   ‚îú‚îÄ‚îÄ smart_locator.py
‚îÇ   ‚îú‚îÄ‚îÄ smart_page.py
‚îÇ   ‚îî‚îÄ‚îÄ framework_adapter.py
‚îî‚îÄ‚îÄ ai_healer.py


The AI interaction is routed through:

services/locator_repair/repair_service.py
services/locator_repair/ai_gateway.py

üß∞ Work to Do
1Ô∏è‚É£ Add AI-Healing Cache Layer

Create or extend a local cache in ai_healer.py:

Store previously healed locator pairs:
(failed_locator + context_hint) ‚Üí healed_locator

Save to logs/healing_cache.json

On subsequent failures:

Check cache first

If found, skip API call

If not found, call AI provider and cache result

# Example snippet
cache_key = f"{framework}:{failed_locator}:{context_hint}"
if cache_key in self.cache:
    return self.cache[cache_key]
else:
    healed = self.call_ai(...)
    self.cache[cache_key] = healed
    self.save_cache()

2Ô∏è‚É£ Add Retry + Backoff Logic for AI Calls

Wrap all AI calls with a retry loop (max 3 attempts).

Use exponential backoff (1s ‚Üí 2s ‚Üí 4s).

Handle errors gracefully (Timeout, ConnectionError, or malformed AI response).

Log retries cleanly.

for attempt in range(3):
    try:
        healed = ai_gateway.ask(prompt)
        break
    except Exception as e:
        wait = 2 ** attempt
        time.sleep(wait)
        if attempt == 2:
            log.error(f"AI healing failed after 3 attempts: {e}")
            return failed_locator

3Ô∏è‚É£ Improve AI Response Sanitization

Some AI responses still include markdown or JSON.

Add a sanitizer utility in ai_healer.py:

Remove backticks, quotes, markdown, and explanations.

Extract the first valid locator string from text or JSON.

def clean_ai_response(resp: str) -> str:
    if resp.startswith("```"): resp = resp.strip("`")
    resp = resp.strip('`"\' ')
    if "locator" in resp.lower():
        resp = resp.split(":")[-1].strip()
    return resp.split("\n")[0]

4Ô∏è‚É£ Enhance SmartLocator Logging

Improve logs in logs/healing_log.json to include:

healing_source: "cache" | "ai" | "fallback"

latency_ms: total repair time

confidence: optional field from AI if provided

Use Python time.perf_counter() to track elapsed healing time.

5Ô∏è‚É£ Add Internal Fallback Hierarchy

If AI healing fails completely:

Try context_hint-based heuristic:

Example: "Submit" ‚Üí find button with similar text via framework adapter.

Log fallback usage.

Mark it as "healing_source": "fallback" in logs.

6Ô∏è‚É£ Clean Method Docstrings

Ensure every method in smart_locator.py and ai_healer.py has:

Type hints

One-line summary

Usage example in docstring

Example:

def heal_locator(self, page, failed_locator: str, context_hint: str = "") -> str:
    """
    Attempt to repair a failed locator using AI or cached results.
    
    Args:
        page (Any): Framework page/driver instance
        failed_locator (str): The broken locator string
        context_hint (str): Optional context for AI healing
        
    Returns:
        str: Repaired locator string
    """

7Ô∏è‚É£ Unit Tests for Optimization

Create a new test file:

tests/test_ai_healer_optimization.py


Test cases:

‚úÖ Healing cache hit (no API call)

‚úÖ Healing cache miss (API called)

‚úÖ Retry logic (simulate failure, then success)

‚úÖ Response cleaning (remove markdown)

‚úÖ Fallback recovery

‚úÖ Log structure validation (fields present)

üì¶ Deliverables

Updated core/ai_healer.py

Updated core/smart_locator/smart_locator.py

New file tests/test_ai_healer_optimization.py

Updated logs/healing_log.json and new logs/healing_cache.json

Updated docstrings and inline comments
=====================================================================
Next Action Steps

1Ô∏è‚É£ Integrate new AI-Healer

Replace the existing ai_healer.py in your repo with Ram‚Äôs optimized version.

Ensure the caching and logging directories (/cache, /logs) exist.

2Ô∏è‚É£ Run validation tests

pytest -v tests/test_ai_healer_optimization.py


confirm 100 % pass rate.

3Ô∏è‚É£ Wire back into SmartLocator
update import:

from core.ai_healer import AIHealer


and confirm caching path consistency.

4Ô∏è‚É£ Push to Git
commit as:

feat(ai_healer): integrate enterprise-grade optimized AIHealer from Ram


5Ô∏è‚É£ Proceed to Vision Testing module
once the healer is verified, we move to Phase 4 ‚Äì Vision LLM visual validation.